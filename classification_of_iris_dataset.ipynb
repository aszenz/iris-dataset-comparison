{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Iris Plants Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# the features (cols) in the dataset\n",
    "col_header=['sepal length(cm)', 'sepal width(cm)', 'petal length(cm)', 'petal width(cm)', 'iris class(cm)']\n",
    "\n",
    "# read file with no headers and col names as mentioned in the above array\n",
    "# the data is in pandas dataframe type\n",
    "iris_panda_set = pd.read_csv('data/iris.data', header=None, names=col_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length(cm)</th>\n",
       "      <th>sepal width(cm)</th>\n",
       "      <th>petal length(cm)</th>\n",
       "      <th>petal width(cm)</th>\n",
       "      <th>iris class(cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length(cm)  sepal width(cm)  petal length(cm)  petal width(cm)  \\\n",
       "0               5.1              3.5               1.4              0.2   \n",
       "1               4.9              3.0               1.4              0.2   \n",
       "2               4.7              3.2               1.3              0.2   \n",
       "3               4.6              3.1               1.5              0.2   \n",
       "4               5.0              3.6               1.4              0.2   \n",
       "5               5.4              3.9               1.7              0.4   \n",
       "6               4.6              3.4               1.4              0.3   \n",
       "7               5.0              3.4               1.5              0.2   \n",
       "8               4.4              2.9               1.4              0.2   \n",
       "9               4.9              3.1               1.5              0.1   \n",
       "\n",
       "  iris class(cm)  \n",
       "0    Iris-setosa  \n",
       "1    Iris-setosa  \n",
       "2    Iris-setosa  \n",
       "3    Iris-setosa  \n",
       "4    Iris-setosa  \n",
       "5    Iris-setosa  \n",
       "6    Iris-setosa  \n",
       "7    Iris-setosa  \n",
       "8    Iris-setosa  \n",
       "9    Iris-setosa  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_panda_set.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length(cm)            5.1\n",
      "sepal width(cm)             3.5\n",
      "petal length(cm)            1.4\n",
      "petal width(cm)             0.2\n",
      "iris class(cm)      Iris-setosa\n",
      "Name: 0, dtype: object\n",
      "sepal length(cm)                  5\n",
      "sepal width(cm)                   2\n",
      "petal length(cm)                3.5\n",
      "petal width(cm)                   1\n",
      "iris class(cm)      Iris-versicolor\n",
      "Name: 60, dtype: object\n",
      "sepal length(cm)               6.9\n",
      "sepal width(cm)                3.2\n",
      "petal length(cm)               5.7\n",
      "petal width(cm)                2.3\n",
      "iris class(cm)      Iris-virginica\n",
      "Name: 120, dtype: object\n",
      "sepal length(cm)    5.1\n",
      "sepal width(cm)     3.5\n",
      "petal length(cm)    1.4\n",
      "petal width(cm)     0.2\n",
      "iris class(cm)      0.0\n",
      "Name: 0, dtype: float64\n",
      "sepal length(cm)    5.0\n",
      "sepal width(cm)     2.0\n",
      "petal length(cm)    3.5\n",
      "petal width(cm)     1.0\n",
      "iris class(cm)      1.0\n",
      "Name: 60, dtype: float64\n",
      "sepal length(cm)    6.9\n",
      "sepal width(cm)     3.2\n",
      "petal length(cm)    5.7\n",
      "petal width(cm)     2.3\n",
      "iris class(cm)      2.0\n",
      "Name: 120, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# change all categorical types to numeric ones\n",
    "print(iris_panda_set.loc[0, :])\n",
    "print(iris_panda_set.loc[60, :])\n",
    "print(iris_panda_set.loc[120, :])\n",
    "\n",
    "# map iris class types to numeric values\n",
    "iris_class_map = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2 }\n",
    "# change the dataset accordingly\n",
    "iris_panda_set['iris class(cm)'] = iris_panda_set['iris class(cm)'].map(iris_class_map)\n",
    "print(iris_panda_set.loc[0, :])\n",
    "print(iris_panda_set.loc[60, :])\n",
    "print(iris_panda_set.loc[120, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stratified ShuffleSplit cross-validator\n",
    "# Provides train/test indices to split data in train/test sets\n",
    "# This cross-validation object is a merge of StratifiedKFold and ShuffleSplit, which returns stratified randomized folds.\n",
    "# The folds are made by preserving the percentage of samples for each class.\n",
    "from sklearn.model_selection import StratifiedShuffleSplit # import training test split method from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we define the feature cols and predicted col\n",
    "feature_col_names = ['sepal length(cm)', 'sepal width(cm)', 'petal length(cm)', 'petal width(cm)']\n",
    "predicted_class_names = ['iris class(cm)']\n",
    "\n",
    "# split our data into two data frames one containing the features cols and other with the iris category\n",
    "X = iris_panda_set[feature_col_names].values # predictor feature cols (4)\n",
    "# predicated class Iris-setosa: 0, Iris-versicolor: 1, Iris-virginica: 2\n",
    "Y = iris_panda_set[predicted_class_names].values # one-d array\n",
    "\n",
    "split_test_size = 0.30 # define the train_test split ratio 30%\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=3, test_size=split_test_size, random_state=20)\n",
    "\n",
    "for train_index, test_index in sss.split(X, Y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.00% in training set\n",
      "30.00% in test set\n"
     ]
    }
   ],
   "source": [
    "#  we check to ensure we have the desired 70% train and 30% test split of the data\n",
    "#  here df.index is the whole data frame\n",
    "print('{0:0.2f}% in training set'.format((len(X_train) / len(iris_panda_set.index)) * 100))\n",
    "print('{0:0.2f}% in test set'.format((len(X_test) / len(iris_panda_set.index)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of setosa plants: 50 (33.33%)\n",
      "Number of versicolor plants: 50 (33.33%)\n",
      "Number of virginica plants: 50 (33.33%)\n",
      "Number of setosa plants in train set: 35 (33.33%)\n",
      "Number of versicolor plants in train set : 35 (33.33%)\n",
      "Number of virginica plants in train set: 35 (33.33%)\n",
      "Number of setosa plants in test set: 15 (33.33%)\n",
      "Number of versicolor plants in test set : 15 (33.33%)\n",
      "Number of virginica plants in test set: 15 (33.33%)\n"
     ]
    }
   ],
   "source": [
    "# We also verify the predicted values were split the same b/w the train & test data sets\n",
    "num_setosa = len(iris_panda_set.loc[iris_panda_set['iris class(cm)'] == 0.0])\n",
    "num_versicolor = len(iris_panda_set.loc[iris_panda_set['iris class(cm)'] == 1.0])\n",
    "num_virginica = len(iris_panda_set.loc[iris_panda_set['iris class(cm)'] == 2.0])\n",
    "total = num_setosa + num_versicolor + num_virginica\n",
    "percentage_setosa = (num_setosa / total) * 100\n",
    "percentage_versicolor = (num_versicolor / total) * 100\n",
    "percentage_virginica = (num_virginica / total) * 100\n",
    "print('Number of setosa plants: {0} ({1:2.2f}%)'.format(num_setosa, percentage_setosa))\n",
    "print('Number of versicolor plants: {0} ({1:2.2f}%)'.format(num_versicolor, percentage_versicolor))\n",
    "print('Number of virginica plants: {0} ({1:2.2f}%)'.format(num_virginica, percentage_virginica))\n",
    "\n",
    "num_setosa_in_train = len(Y_train[Y_train[:] == 0.0])\n",
    "num_versicolor_in_train = len(Y_train[Y_train[:] == 1.0])\n",
    "num_virginica_in_train = len(Y_train[Y_train[:] == 2.0])\n",
    "total_in_train = num_setosa_in_train + num_versicolor_in_train + num_virginica_in_train\n",
    "percentage_setosa_in_train = (num_setosa_in_train / total_in_train) * 100\n",
    "percentage_versicolor_in_train = (num_versicolor_in_train / total_in_train) * 100\n",
    "percentage_virginica_in_train = (num_virginica_in_train / total_in_train) * 100\n",
    "\n",
    "# printing the result\n",
    "print('Number of setosa plants in train set: {0} ({1:2.2f}%)'.format(num_setosa_in_train, percentage_setosa_in_train))\n",
    "print('Number of versicolor plants in train set : {0} ({1:2.2f}%)'.format(num_versicolor_in_train, percentage_versicolor_in_train))\n",
    "print('Number of virginica plants in train set: {0} ({1:2.2f}%)'.format(num_virginica_in_train, percentage_virginica_in_train))\n",
    "\n",
    "num_setosa_in_test = len(Y_test[Y_test[:] == 0.0])\n",
    "num_versicolor_in_test = len(Y_test[Y_test[:] == 1.0])\n",
    "num_virginica_in_test = len(Y_test[Y_test[:] == 2.0])\n",
    "total_in_test = num_setosa_in_test + num_versicolor_in_test + num_virginica_in_test\n",
    "percentage_setosa_in_test = (num_setosa_in_test / total_in_test) * 100\n",
    "percentage_versicolor_in_test = (num_versicolor_in_test / total_in_test) * 100\n",
    "percentage_virginica_in_test = (num_virginica_in_test / total_in_test) * 100\n",
    "\n",
    "# printing the result\n",
    "print('Number of setosa plants in test set: {0} ({1:2.2f}%)'.format(num_setosa_in_test, percentage_setosa_in_test))\n",
    "print('Number of versicolor plants in test set : {0} ({1:2.2f}%)'.format(num_versicolor_in_test, percentage_versicolor_in_test))\n",
    "print('Number of virginica plants in test set: {0} ({1:2.2f}%)'.format(num_virginica_in_test, percentage_virginica_in_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import Naive Bayes algorithm from the library\n",
    "# In case of naive_bayes there are multiple implementations \n",
    "# we are using the gaussian algo that assumes that the feature data is distributed in a gaussian \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# create Gaussian Naive Bayes model object and train it with data\n",
    "nb_model = GaussianNB() # our model object\n",
    "\n",
    "# call the fit method to create a model trained with the training data \n",
    "# numpy.ravel returns a contiguous flattened array\n",
    "nb_model.fit(X_train, Y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of Naive Bayes on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(%) of NB model on test data:  95.5556\n",
      "\n",
      "Classification report of NB model:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        15\n",
      "          1       0.93      0.93      0.93        15\n",
      "          2       0.93      0.93      0.93        15\n",
      "\n",
      "avg / total       0.96      0.96      0.96        45\n",
      "\n",
      "Here:\n",
      " 0 -> Iris-setosa \n",
      " 1 -> Iris-versicolor \n",
      " 2 -> Iris-virginica \n"
     ]
    }
   ],
   "source": [
    "# to see the accuracy we load the scikit metrics library\n",
    "# metrics has methods that let us get the statistics on the models predictive performance\n",
    "from sklearn import metrics\n",
    "# Now lets predict against the testing data\n",
    "# X_test is the data we kept aside for testing\n",
    "nb_predict_test = nb_model.predict(X_test)\n",
    "# Y_test is the actual output and nb_predict_test is the predicted one \n",
    "test_accuracy = metrics.accuracy_score(Y_test, nb_predict_test)\n",
    "print('Accuracy(%) of NB model on test data: {0: .4f}'.format(test_accuracy * 100))\n",
    "# the classification report generates statistics based on the values shown in the confusion matrix.\n",
    "print('\\nClassification report of NB model:\\n')\n",
    "print(metrics.classification_report(Y_test, nb_predict_test, labels = [0, 1, 2]))\n",
    "print('Here:\\n 0 -> Iris-setosa \\n 1 -> Iris-versicolor \\n 2 -> Iris-virginica ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=54, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import random forest from scikit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state = 54) # Create random forest object\n",
    "rf_model.fit(X_train, Y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of Random Forest on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(%) of RF model on test data: 93.3333\n",
      "\n",
      "Classification report of RF model:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        15\n",
      "          1       0.93      0.87      0.90        15\n",
      "          2       0.88      0.93      0.90        15\n",
      "\n",
      "avg / total       0.93      0.93      0.93        45\n",
      "\n",
      "Here:\n",
      " 0 -> Iris-setosa \n",
      " 1 -> Iris-versicolor \n",
      " 2 -> Iris-virginica \n"
     ]
    }
   ],
   "source": [
    "rf_predict_test = rf_model.predict(X_test)\n",
    "# training metrics\n",
    "print('Accuracy(%) of RF model on test data: {0:.4f}'.format((metrics.accuracy_score(Y_test, rf_predict_test)) * 100))\n",
    "print('\\nClassification report of RF model:\\n')\n",
    "print(metrics.classification_report(Y_test, rf_predict_test, labels = [0, 1, 2]))\n",
    "print('Here:\\n 0 -> Iris-setosa \\n 1 -> Iris-versicolor \\n 2 -> Iris-virginica ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scikit learn has an ensemble algorithm that combines logistic regression with cross validation called LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=3, class_weight=None, cv=10, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv_model = LogisticRegressionCV(Cs=3, refit=True, cv=10,)\n",
    "lr_cv_model.fit(X_train, Y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of LR on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(%) of LRCV model on test data: 95.5556\n",
      "\n",
      "Classification report of LRCV model:\n",
      " \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        15\n",
      "          1       0.93      0.93      0.93        15\n",
      "          2       0.93      0.93      0.93        15\n",
      "\n",
      "avg / total       0.96      0.96      0.96        45\n",
      "\n",
      "Here:\n",
      " 0 -> Iris-setosa \n",
      " 1 -> Iris-versicolor \n",
      " 2 -> Iris-virginica \n"
     ]
    }
   ],
   "source": [
    "lr_cv_predict_test = lr_cv_model.predict(X_test)\n",
    "# training metrics\n",
    "print('Accuracy(%) of LRCV model on test data: {0:.4f}'.format((metrics.accuracy_score(Y_test, lr_cv_predict_test)) * 100))\n",
    "print('\\nClassification report of LRCV model:\\n ')\n",
    "print(metrics.classification_report(Y_test, lr_cv_predict_test, labels = [0, 1, 2]))\n",
    "print('Here:\\n 0 -> Iris-setosa \\n 1 -> Iris-versicolor \\n 2 -> Iris-virginica ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training MLP (simple NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(3, 3, 3), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=20000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the algorithm\n",
    "# Multi-layer Perceptron (MLP) is a supervised learning algorithm\n",
    "# MLPClassifier implements a multi-layer perceptron (MLP) algorithm \n",
    "    # that trains using Backpropagation.\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# initialize the MLP classifier model with parameters\n",
    "nn_model = MLPClassifier(hidden_layer_sizes=((3, 3, 3)), max_iter=20000)\n",
    "# train the model with the training set inputs and outputs \n",
    "nn_model.fit(X_train, Y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of MLP on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(%) of MLP model on test data: 97.7778\n",
      "\n",
      "Classification report of MLP model:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        15\n",
      "          1       1.00      0.93      0.97        15\n",
      "          2       0.94      1.00      0.97        15\n",
      "\n",
      "avg / total       0.98      0.98      0.98        45\n",
      "\n",
      "Here:\n",
      " 0 -> Iris-setosa \n",
      " 1 -> Iris-versicolor \n",
      " 2 -> Iris-virginica \n"
     ]
    }
   ],
   "source": [
    "nn_predict_test = nn_model.predict(X_test)\n",
    "# training metrics\n",
    "print('Accuracy(%) of MLP model on test data: {0:.4f}'.format((metrics.accuracy_score(Y_test, nn_predict_test)) * 100))\n",
    "print('\\nClassification report of MLP model:\\n')\n",
    "print(metrics.classification_report(Y_test, nn_predict_test, labels = [0, 1, 2]))\n",
    "print('Here:\\n 0 -> Iris-setosa \\n 1 -> Iris-versicolor \\n 2 -> Iris-virginica ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# Create a classifier: a support vector classifier\n",
    "svm_model = svm.SVC(gamma=0.001)\n",
    "svm_model.fit(X_train, Y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of SVM on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(%) of SVM model on test data: 93.3333\n",
      "\n",
      "Classification report of SVM model:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        15\n",
      "          1       0.88      0.93      0.90        15\n",
      "          2       0.93      0.87      0.90        15\n",
      "\n",
      "avg / total       0.93      0.93      0.93        45\n",
      "\n",
      "Here:\n",
      " 0 -> Iris-setosa \n",
      " 1 -> Iris-versicolor \n",
      " 2 -> Iris-virginica \n"
     ]
    }
   ],
   "source": [
    "svm_predict_test = svm_model.predict(X_test)\n",
    "# training metrics\n",
    "print('Accuracy(%) of SVM model on test data: {0:.4f}'.format((metrics.accuracy_score(Y_test, svm_predict_test)) * 100))\n",
    "print('\\nClassification report of SVM model:\\n')\n",
    "print(metrics.classification_report(Y_test, svm_predict_test, labels = [0, 1, 2]))\n",
    "print('Here:\\n 0 -> Iris-setosa \\n 1 -> Iris-versicolor \\n 2 -> Iris-virginica ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
